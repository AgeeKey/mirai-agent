#!/usr/bin/env python3
"""
Mirai Machine Learning & Adaptive System
–°–∏—Å—Ç–µ–º–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ–º –æ–ø—ã—Ç–∞
"""

import asyncio
import logging
import json
import numpy as np
import pandas as pd
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, asdict
from pathlib import Path
import pickle
import hashlib
import time
import sys
import os
from collections import defaultdict, deque
import random
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –ò–ò –º–æ–¥—É–ª–µ–π
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from ai_integration import MiraiAICoordinator
    from knowledge_base import MiraiKnowledgeBase
    from intelligent_algorithms import IntelligentAlgorithmManager
    from autonomous_content_engine import MiraiContentEngine
    AI_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è –ò–ò –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")
    AI_AVAILABLE = False

@dataclass
class LearningExperience:
    """–û–ø—ã—Ç –æ–±—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
    experience_id: str
    timestamp: datetime
    context: Dict[str, Any]
    action_taken: str
    outcome: Dict[str, Any]
    reward: float
    confidence: float
    learning_type: str  # prediction, trading, content, optimization
    metadata: Dict[str, Any]

@dataclass
class ModelPerformance:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    model_id: str
    model_type: str
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    mse: float
    r2_score: float
    training_time: float
    prediction_time: float
    last_updated: datetime

class AdaptiveModel:
    """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, model_type: str, model_id: str):
        self.model_type = model_type
        self.model_id = model_id
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.performance_history = []
        self.feature_importance = {}
        self.last_training = None
        self.training_data = []
        self.prediction_cache = {}
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
        self.adaptation_threshold = 0.1  # –ü–æ—Ä–æ–≥ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        self.max_training_samples = 10000
        self.retrain_frequency = timedelta(hours=6)
        
        self.initialize_model()
    
    def initialize_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞"""
        if self.model_type == 'price_prediction':
            self.model = RandomForestRegressor(
                n_estimators=100,
                random_state=42,
                n_jobs=-1
            )
        elif self.model_type == 'signal_classification':
            self.model = GradientBoostingClassifier(
                n_estimators=100,
                random_state=42
            )
        elif self.model_type == 'content_quality':
            self.model = RandomForestRegressor(
                n_estimators=50,
                random_state=42
            )
        else:
            # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
            self.model = RandomForestRegressor(
                n_estimators=75,
                random_state=42
            )
    
    def add_training_data(self, features: np.ndarray, targets: np.ndarray, context: Dict = None):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        self.training_data.append({
            'features': features,
            'targets': targets,
            'timestamp': datetime.now(),
            'context': context or {}
        })
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if len(self.training_data) > self.max_training_samples:
            self.training_data = self.training_data[-self.max_training_samples:]
    
    def should_retrain(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        if not self.last_training:
            return len(self.training_data) > 50
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        time_passed = datetime.now() - self.last_training
        if time_passed > self.retrain_frequency:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        recent_data = [
            d for d in self.training_data 
            if d['timestamp'] > self.last_training
        ]
        
        return len(recent_data) > 100
    
    async def train_model(self) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if len(self.training_data) < 10:
            return {'status': 'insufficient_data', 'samples': len(self.training_data)}
        
        start_time = time.time()
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            all_features = []
            all_targets = []
            
            for data_point in self.training_data:
                features = data_point['features']
                targets = data_point['targets']
                
                if features.ndim == 1:
                    features = features.reshape(1, -1)
                
                all_features.append(features)
                all_targets.extend(targets if isinstance(targets, (list, np.ndarray)) else [targets])
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            X = np.vstack(all_features)
            y = np.array(all_targets)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            X_scaled = self.scaler.fit_transform(X)
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
            if len(X_scaled) > 20:
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=0.2, random_state=42
                )
            else:
                X_train, X_test = X_scaled, X_scaled
                y_train, y_test = y, y
            
            # –û–±—É—á–µ–Ω–∏–µ
            self.model.fit(X_train, y_train)
            
            # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            train_predictions = self.model.predict(X_train)
            test_predictions = self.model.predict(X_test)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            performance = {
                'train_r2': r2_score(y_train, train_predictions) if len(y_train) > 1 else 0,
                'test_r2': r2_score(y_test, test_predictions) if len(y_test) > 1 else 0,
                'train_mse': mean_squared_error(y_train, train_predictions),
                'test_mse': mean_squared_error(y_test, test_predictions),
                'training_time': time.time() - start_time,
                'training_samples': len(X_train),
                'test_samples': len(X_test),
                'feature_count': X.shape[1]
            }
            
            # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if hasattr(self.model, 'feature_importances_'):
                self.feature_importance = {
                    f'feature_{i}': importance 
                    for i, importance in enumerate(self.model.feature_importances_)
                }
            
            self.performance_history.append(performance)
            self.last_training = datetime.now()
            
            return {
                'status': 'success',
                'performance': performance,
                'model_id': self.model_id,
                'training_samples': len(self.training_data)
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'model_id': self.model_id
            }
    
    def predict(self, features: np.ndarray, cache_key: str = None) -> Dict[str, Any]:
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        if self.model is None:
            return {'error': 'Model not trained'}
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        if cache_key and cache_key in self.prediction_cache:
            return self.prediction_cache[cache_key]
        
        start_time = time.time()
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            if features.ndim == 1:
                features = features.reshape(1, -1)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            features_scaled = self.scaler.transform(features)
            
            # –ü—Ä–æ–≥–Ω–æ–∑
            prediction = self.model.predict(features_scaled)
            
            # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ - —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–æ–≤)
            confidence = 0.8  # –ó–∞–≥–ª—É—à–∫–∞, –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
            
            result = {
                'prediction': prediction.tolist() if isinstance(prediction, np.ndarray) else prediction,
                'confidence': confidence,
                'prediction_time': time.time() - start_time,
                'model_id': self.model_id,
                'features_count': features.shape[1]
            }
            
            # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            if cache_key:
                self.prediction_cache[cache_key] = result
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞
                if len(self.prediction_cache) > 1000:
                    keys_to_remove = list(self.prediction_cache.keys())[:100]
                    for key in keys_to_remove:
                        del self.prediction_cache[key]
            
            return result
            
        except Exception as e:
            return {'error': str(e)}

class MiraiLearningEngine:
    """–î–≤–∏–∂–æ–∫ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"""
    
    def __init__(self):
        self.logger = self.setup_logging()
        self.db_path = '/root/mirai-agent/state/learning_engine.db'
        self.models_path = '/root/mirai-agent/models'
        self.experiences_path = '/root/mirai-agent/experiences'
        
        # –ò–ò –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if AI_AVAILABLE:
            self.ai_coordinator = MiraiAICoordinator()
            self.knowledge_base = MiraiKnowledgeBase()
            self.algorithm_manager = IntelligentAlgorithmManager()
            self.content_engine = MiraiContentEngine()
        else:
            self.ai_coordinator = None
            self.knowledge_base = None
            self.algorithm_manager = None
            self.content_engine = None
        
        # –ú–æ–¥–µ–ª–∏
        self.models = {}
        self.model_performance = {}
        
        # –û–ø—ã—Ç –æ–±—É—á–µ–Ω–∏—è
        self.experiences = deque(maxlen=100000)
        self.learning_stats = {
            'total_experiences': 0,
            'models_trained': 0,
            'predictions_made': 0,
            'avg_accuracy': 0.0,
            'start_time': datetime.now()
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è
        self.learning_config = {
            'auto_retrain': True,
            'experience_batch_size': 100,
            'min_samples_for_training': 50,
            'performance_threshold': 0.7,
            'learning_rate_decay': 0.95,
            'exploration_rate': 0.1
        }
        
        self.init_database()
        self.ensure_directories()
        self.initialize_models()
    
    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('/root/mirai-agent/logs/learning_engine.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger('LearningEngine')
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        Path(self.db_path).parent.mkdir(exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            # –¢–∞–±–ª–∏—Ü–∞ –æ–ø—ã—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
            conn.execute('''
                CREATE TABLE IF NOT EXISTS learning_experiences (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    experience_id TEXT UNIQUE NOT NULL,
                    timestamp TEXT NOT NULL,
                    context TEXT NOT NULL,
                    action_taken TEXT NOT NULL,
                    outcome TEXT NOT NULL,
                    reward REAL NOT NULL,
                    confidence REAL NOT NULL,
                    learning_type TEXT NOT NULL,
                    metadata TEXT NOT NULL
                )
            ''')
            
            # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
            conn.execute('''
                CREATE TABLE IF NOT EXISTS model_performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    model_id TEXT NOT NULL,
                    model_type TEXT NOT NULL,
                    accuracy REAL NOT NULL,
                    precision_score REAL NOT NULL,
                    recall_score REAL NOT NULL,
                    f1_score REAL NOT NULL,
                    mse REAL NOT NULL,
                    r2_score REAL NOT NULL,
                    training_time REAL NOT NULL,
                    prediction_time REAL NOT NULL,
                    last_updated TEXT NOT NULL
                )
            ''')
            
            # –¢–∞–±–ª–∏—Ü–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–π —Å–∏—Å—Ç–µ–º—ã
            conn.execute('''
                CREATE TABLE IF NOT EXISTS system_adaptations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    adaptation_type TEXT NOT NULL,
                    adaptation_data TEXT NOT NULL,
                    performance_before REAL NOT NULL,
                    performance_after REAL NOT NULL,
                    timestamp TEXT NOT NULL,
                    success BOOLEAN DEFAULT TRUE
                )
            ''')
            
            conn.commit()
    
    def ensure_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        directories = [
            self.models_path,
            self.experiences_path,
            '/root/mirai-agent/learning_reports'
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def initialize_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        model_configs = [
            ('price_prediction', '–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω –∞–∫—Ç–∏–≤–æ–≤'),
            ('signal_classification', '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤'),
            ('content_quality', '–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞'),
            ('market_sentiment', '–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Ä—ã–Ω–∫–∞'),
            ('risk_assessment', '–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤'),
            ('portfolio_optimization', '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è')
        ]
        
        for model_type, description in model_configs:
            model_id = f"mirai_{model_type}_{datetime.now().strftime('%Y%m%d')}"
            self.models[model_type] = AdaptiveModel(model_type, model_id)
            self.logger.info(f"ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_type}")
    
    async def add_learning_experience(self, context: Dict[str, Any], action: str, 
                                    outcome: Dict[str, Any], reward: float,
                                    learning_type: str = 'general') -> str:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–ø—ã—Ç–∞ –æ–±—É—á–µ–Ω–∏—è"""
        experience_id = hashlib.md5(
            f"{datetime.now().isoformat()}_{action}_{learning_type}".encode()
        ).hexdigest()
        
        experience = LearningExperience(
            experience_id=experience_id,
            timestamp=datetime.now(),
            context=context,
            action_taken=action,
            outcome=outcome,
            reward=reward,
            confidence=outcome.get('confidence', 0.5),
            learning_type=learning_type,
            metadata={'source': 'autonomous_learning'}
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ø–∞–º—è—Ç—å
        self.experiences.append(experience)
        self.learning_stats['total_experiences'] += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        self.save_experience_to_db(experience)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        await self.update_models_with_experience(experience)
        
        self.logger.info(f"üìö –î–æ–±–∞–≤–ª–µ–Ω –æ–ø—ã—Ç –æ–±—É—á–µ–Ω–∏—è: {learning_type} - –Ω–∞–≥—Ä–∞–¥–∞: {reward:.3f}")
        
        return experience_id
    
    def save_experience_to_db(self, experience: LearningExperience):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–ø—ã—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO learning_experiences 
                (experience_id, timestamp, context, action_taken, outcome, 
                 reward, confidence, learning_type, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                experience.experience_id,
                experience.timestamp.isoformat(),
                json.dumps(experience.context, ensure_ascii=False),
                experience.action_taken,
                json.dumps(experience.outcome, ensure_ascii=False),
                experience.reward,
                experience.confidence,
                experience.learning_type,
                json.dumps(experience.metadata, ensure_ascii=False)
            ))
    
    async def update_models_with_experience(self, experience: LearningExperience):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞"""
        learning_type = experience.learning_type
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª—è—Ç—å
            if learning_type in ['trading', 'signal']:
                await self.update_trading_models(experience)
            elif learning_type in ['content', 'article']:
                await self.update_content_models(experience)
            elif learning_type in ['prediction', 'forecast']:
                await self.update_prediction_models(experience)
            elif learning_type == 'risk':
                await self.update_risk_models(experience)
            
            # –û–±—â–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            await self.update_general_models(experience)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
    
    async def update_trading_models(self, experience: LearningExperience):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        if 'signal_classification' in self.models:
            model = self.models['signal_classification']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context = experience.context
            features = self.extract_trading_features(context)
            
            # –¶–µ–ª—å - —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞
            target = 1 if experience.reward > 0 else 0
            
            if features is not None:
                model.add_training_data(features, np.array([target]), context)
                
                if model.should_retrain():
                    result = await model.train_model()
                    self.logger.info(f"üîÑ –ú–æ–¥–µ–ª—å signal_classification –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞: {result['status']}")
    
    async def update_content_models(self, experience: LearningExperience):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        if 'content_quality' in self.models:
            model = self.models['content_quality']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            context = experience.context
            features = self.extract_content_features(context)
            
            # –¶–µ–ª—å - –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            target = experience.reward
            
            if features is not None:
                model.add_training_data(features, np.array([target]), context)
                
                if model.should_retrain():
                    result = await model.train_model()
                    self.logger.info(f"üîÑ –ú–æ–¥–µ–ª—å content_quality –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞: {result['status']}")
    
    async def update_prediction_models(self, experience: LearningExperience):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        if 'price_prediction' in self.models:
            model = self.models['price_prediction']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            context = experience.context
            features = self.extract_market_features(context)
            
            # –¶–µ–ª—å - —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–∞ –∏–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
            target = experience.outcome.get('actual_price', experience.reward)
            
            if features is not None:
                model.add_training_data(features, np.array([target]), context)
                
                if model.should_retrain():
                    result = await model.train_model()
                    self.logger.info(f"üîÑ –ú–æ–¥–µ–ª—å price_prediction –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞: {result['status']}")
    
    async def update_risk_models(self, experience: LearningExperience):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Ä–∏—Å–∫–∞"""
        if 'risk_assessment' in self.models:
            model = self.models['risk_assessment']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∏—Å–∫–∞
            context = experience.context
            features = self.extract_risk_features(context)
            
            # –¶–µ–ª—å - —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞
            target = experience.outcome.get('risk_level', abs(experience.reward))
            
            if features is not None:
                model.add_training_data(features, np.array([target]), context)
                
                if model.should_retrain():
                    result = await model.train_model()
                    self.logger.info(f"üîÑ –ú–æ–¥–µ–ª—å risk_assessment –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞: {result['status']}")
    
    async def update_general_models(self, experience: LearningExperience):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—â–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Ä—ã–Ω–∫–∞
        if 'market_sentiment' in self.models:
            model = self.models['market_sentiment']
            context = experience.context
            
            # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
            features = np.array([
                experience.reward,
                experience.confidence,
                hash(experience.action_taken) % 100,
                len(str(experience.outcome))
            ]).reshape(1, -1)
            
            sentiment_score = (experience.reward + 1) / 2  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ [0, 1]
            
            model.add_training_data(features, np.array([sentiment_score]), context)
    
    def extract_trading_features(self, context: Dict[str, Any]) -> Optional[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            features = []
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            market_data = context.get('market_data', {})
            features.extend([
                market_data.get('current_price', 0),
                market_data.get('volume_24h', 0),
                market_data.get('price_change_24h', 0),
                market_data.get('volatility', 0),
                market_data.get('rsi', 50)
            ])
            
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            features.extend([
                1 if market_data.get('trend_direction') == 'up' else 0,
                1 if market_data.get('macd_signal') == 'buy' else 0,
                len(market_data.get('support_levels', [])),
                len(market_data.get('resistance_levels', []))
            ])
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            now = datetime.now()
            features.extend([
                now.hour,
                now.weekday(),
                now.month
            ])
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None
    
    def extract_content_features(self, context: Dict[str, Any]) -> Optional[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–µ–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        try:
            features = []
            
            # –ú–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content_data = context.get('content_data', {})
            features.extend([
                content_data.get('word_count', 0),
                content_data.get('section_count', 0),
                content_data.get('ai_confidence', 0.5),
                len(content_data.get('topics', [])),
                content_data.get('readability_score', 0.5)
            ])
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞—É–¥–∏—Ç–æ—Ä–∏–∏
            features.extend([
                1 if content_data.get('target_audience') == 'professional' else 0,
                1 if content_data.get('content_type') == 'analysis' else 0,
                content_data.get('complexity_level', 5)
            ])
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            now = datetime.now()
            features.extend([
                now.hour,
                1 if now.weekday() < 5 else 0  # —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å
            ])
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            return None
    
    def extract_market_features(self, context: Dict[str, Any]) -> Optional[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            features = []
            
            # –ë–∞–∑–æ–≤—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            market_data = context.get('market_data', {})
            features.extend([
                market_data.get('current_price', 0),
                market_data.get('volume_24h', 0),
                market_data.get('price_change_24h', 0),
                market_data.get('volatility', 0),
                market_data.get('market_cap', 0)
            ])
            
            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            features.extend([
                market_data.get('rsi', 50),
                market_data.get('macd', 0),
                market_data.get('bollinger_position', 0.5),
                market_data.get('volume_ratio', 1.0)
            ])
            
            # –í–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            features.extend([
                market_data.get('fear_greed_index', 50),
                1 if market_data.get('market_sentiment') == 'bullish' else 0
            ])
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None
    
    def extract_risk_features(self, context: Dict[str, Any]) -> Optional[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–∏—Å–∫–∞"""
        try:
            features = []
            
            # –î–∞–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏
            position_data = context.get('position_data', {})
            features.extend([
                position_data.get('position_size', 0),
                position_data.get('leverage', 1),
                position_data.get('stop_loss_distance', 0),
                position_data.get('take_profit_distance', 0)
            ])
            
            # –†—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            market_data = context.get('market_data', {})
            features.extend([
                market_data.get('volatility', 0),
                market_data.get('volume_24h', 0),
                market_data.get('price_change_24h', 0)
            ])
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏
            now = datetime.now()
            features.extend([
                1 if now.weekday() >= 5 else 0,  # –≤—ã—Ö–æ–¥–Ω—ã–µ
                now.hour,
                1 if 9 <= now.hour <= 16 else 0  # —Ç–æ—Ä–≥–æ–≤—ã–µ —á–∞—Å—ã
            ])
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–∏—Å–∫–∞: {e}")
            return None
    
    async def make_prediction(self, model_type: str, features: Dict[str, Any], 
                            cache_key: str = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏"""
        if model_type not in self.models:
            return {'error': f'Model {model_type} not found'}
        
        model = self.models[model_type]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        if model_type == 'price_prediction':
            feature_array = self.extract_market_features({'market_data': features})
        elif model_type == 'signal_classification':
            feature_array = self.extract_trading_features({'market_data': features})
        elif model_type == 'content_quality':
            feature_array = self.extract_content_features({'content_data': features})
        elif model_type == 'risk_assessment':
            feature_array = self.extract_risk_features(features)
        else:
            # –û–±—â–∏–π —Å–ª—É—á–∞–π
            feature_array = np.array(list(features.values())).reshape(1, -1)
        
        if feature_array is None:
            return {'error': 'Failed to extract features'}
        
        # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
        result = model.predict(feature_array, cache_key)
        
        self.learning_stats['predictions_made'] += 1
        
        self.logger.info(f"üîÆ –ü—Ä–æ–≥–Ω–æ–∑ {model_type}: {result.get('prediction', 'N/A')}")
        
        return result
    
    async def optimize_system_parameters(self) -> Dict[str, Any]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        self.logger.info("‚öôÔ∏è –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã")
        
        optimization_results = {}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π
        for model_type, model in self.models.items():
            if model.performance_history:
                recent_performance = model.performance_history[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –æ–±—É—á–µ–Ω–∏–π
                avg_performance = np.mean([p.get('test_r2', 0) for p in recent_performance])
                
                # –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞–¥–∞–µ—Ç, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                if avg_performance < self.learning_config['performance_threshold']:
                    await self.optimize_model_parameters(model_type, model)
                    optimization_results[model_type] = 'optimized'
                else:
                    optimization_results[model_type] = 'stable'
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        await self.optimize_global_parameters()
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ —Ä—ã–Ω–æ—á–Ω—ã–º —É—Å–ª–æ–≤–∏—è–º
        await self.adapt_to_market_conditions()
        
        self.logger.info(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {optimization_results}")
        
        return {
            'status': 'completed',
            'models_optimized': optimization_results,
            'timestamp': datetime.now().isoformat()
        }
    
    async def optimize_model_parameters(self, model_type: str, model: AdaptiveModel):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        self.logger.info(f"üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ {model_type}")
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        if hasattr(model.model, 'n_estimators'):
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            current_estimators = model.model.n_estimators
            new_estimators = min(current_estimators + 20, 200)
            model.model.n_estimators = new_estimators
            
            self.logger.info(f"üìà {model_type}: n_estimators {current_estimators} ‚Üí {new_estimators}")
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —á–∞—Å—Ç–æ—Ç—É –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        if model.performance_history:
            recent_performance = model.performance_history[-3:]
            if len(recent_performance) >= 2:
                performance_trend = recent_performance[-1].get('test_r2', 0) - recent_performance[-2].get('test_r2', 0)
                
                if performance_trend < 0:  # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞–¥–∞–µ—Ç
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
                    model.retrain_frequency = timedelta(hours=max(1, model.retrain_frequency.total_seconds() / 3600 - 1))
                    self.logger.info(f"‚è∞ {model_type}: —á–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è —É–≤–µ–ª–∏—á–µ–Ω–∞")
    
    async def optimize_global_parameters(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_experiences = len(self.experiences)
        
        if total_experiences > 1000:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            self.learning_config['experience_batch_size'] = min(
                self.learning_config['experience_batch_size'] + 20, 500
            )
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        recent_rewards = [exp.reward for exp in list(self.experiences)[-100:]]
        if recent_rewards:
            avg_reward = np.mean(recent_rewards)
            if avg_reward > 0.7:
                # –°–Ω–∏–∂–∞–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é
                self.learning_config['exploration_rate'] *= 0.95
            elif avg_reward < 0.3:
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
                self.learning_config['exploration_rate'] = min(
                    self.learning_config['exploration_rate'] * 1.05, 0.3
                )
        
        self.logger.info(f"üåê –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã: exploration_rate={self.learning_config['exploration_rate']:.3f}")
    
    async def adapt_to_market_conditions(self):
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ —Ä—ã–Ω–æ—á–Ω—ã–º —É—Å–ª–æ–≤–∏—è–º"""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –æ–ø—ã—Ç—ã
        trading_experiences = [
            exp for exp in list(self.experiences)[-200:]
            if exp.learning_type in ['trading', 'signal']
        ]
        
        if len(trading_experiences) >= 20:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
            rewards_by_condition = defaultdict(list)
            
            for exp in trading_experiences:
                market_sentiment = exp.context.get('market_data', {}).get('market_sentiment', 'neutral')
                rewards_by_condition[market_sentiment].append(exp.reward)
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ–¥ —É—Å–ª–æ–≤–∏—è
            for condition, rewards in rewards_by_condition.items():
                if len(rewards) >= 5:
                    avg_reward = np.mean(rewards)
                    self.logger.info(f"üìä –†—ã–Ω–æ–∫ {condition}: —Å—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ {avg_reward:.3f}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–¥–∞–ø—Ç–∞—Ü–∏—é –≤ –ë–î
                    await self.save_adaptation_result(
                        adaptation_type='market_condition',
                        adaptation_data={'condition': condition, 'avg_reward': avg_reward},
                        performance_improvement=avg_reward
                    )
    
    async def save_adaptation_result(self, adaptation_type: str, adaptation_data: Dict,
                                   performance_improvement: float):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO system_adaptations 
                (adaptation_type, adaptation_data, performance_before, performance_after, timestamp)
                VALUES (?, ?, ?, ?, ?)
            """, (
                adaptation_type,
                json.dumps(adaptation_data, ensure_ascii=False),
                0.5,  # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                performance_improvement,
                datetime.now().isoformat()
            ))
    
    async def generate_learning_report(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        self.logger.info("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º
        model_stats = {}
        for model_type, model in self.models.items():
            if model.performance_history:
                latest_performance = model.performance_history[-1]
                model_stats[model_type] = {
                    'training_samples': len(model.training_data),
                    'latest_r2': latest_performance.get('test_r2', 0),
                    'latest_mse': latest_performance.get('test_mse', 0),
                    'last_trained': model.last_training.isoformat() if model.last_training else None,
                    'performance_trend': self.calculate_performance_trend(model.performance_history)
                }
            else:
                model_stats[model_type] = {'status': 'not_trained'}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–ø—ã—Ç–∞–º
        experiences_by_type = defaultdict(int)
        rewards_by_type = defaultdict(list)
        
        for exp in list(self.experiences)[-1000:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –æ–ø—ã—Ç–æ–≤
            experiences_by_type[exp.learning_type] += 1
            rewards_by_type[exp.learning_type].append(exp.reward)
        
        experience_stats = {}
        for exp_type, count in experiences_by_type.items():
            rewards = rewards_by_type[exp_type]
            experience_stats[exp_type] = {
                'count': count,
                'avg_reward': np.mean(rewards),
                'success_rate': len([r for r in rewards if r > 0]) / len(rewards)
            }
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        uptime = datetime.now() - self.learning_stats['start_time']
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'uptime_hours': uptime.total_seconds() / 3600,
            'total_experiences': self.learning_stats['total_experiences'],
            'predictions_made': self.learning_stats['predictions_made'],
            'models_active': len([m for m in self.models.values() if m.last_training]),
            'model_statistics': model_stats,
            'experience_statistics': experience_stats,
            'learning_config': self.learning_config,
            'system_health': self.assess_system_health()
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_path = f"/root/mirai-agent/learning_reports/learning_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"üìù –û—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        
        return report
    
    def calculate_performance_trend(self, performance_history: List[Dict]) -> str:
        """–†–∞—Å—á–µ—Ç —Ç—Ä–µ–Ω–¥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if len(performance_history) < 2:
            return 'insufficient_data'
        
        recent_scores = [p.get('test_r2', 0) for p in performance_history[-5:]]
        
        if len(recent_scores) >= 3:
            trend = np.polyfit(range(len(recent_scores)), recent_scores, 1)[0]
            
            if trend > 0.01:
                return 'improving'
            elif trend < -0.01:
                return 'declining'
            else:
                return 'stable'
        
        return 'unknown'
    
    def assess_system_health(self) -> str:
        """–û—Ü–µ–Ω–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è"""
        healthy_models = 0
        total_models = len(self.models)
        
        for model in self.models.values():
            if model.performance_history:
                latest_performance = model.performance_history[-1]
                if latest_performance.get('test_r2', 0) > 0.5:
                    healthy_models += 1
        
        health_ratio = healthy_models / total_models if total_models > 0 else 0
        
        if health_ratio >= 0.8:
            return 'excellent'
        elif health_ratio >= 0.6:
            return 'good'
        elif health_ratio >= 0.4:
            return 'fair'
        else:
            return 'poor'
    
    async def autonomous_learning_cycle(self):
        """–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üß† –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")
        
        cycle_count = 0
        
        while True:
            try:
                cycle_count += 1
                self.logger.info(f"üîÑ –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è {cycle_count}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏
                retrain_tasks = []
                for model_type, model in self.models.items():
                    if model.should_retrain():
                        retrain_tasks.append(model.train_model())
                        self.logger.info(f"üîÑ –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ: {model_type}")
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
                if retrain_tasks:
                    results = await asyncio.gather(*retrain_tasks, return_exceptions=True)
                    
                    for i, result in enumerate(results):
                        if isinstance(result, Exception):
                            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {result}")
                        else:
                            self.learning_stats['models_trained'] += 1
                            self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞: {result.get('status', 'unknown')}")
                
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∫–∞–∂–¥—ã–µ 10 —Ü–∏–∫–ª–æ–≤
                if cycle_count % 10 == 0:
                    await self.optimize_system_parameters()
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –∫–∞–∂–¥—ã–µ 20 —Ü–∏–∫–ª–æ–≤
                if cycle_count % 20 == 0:
                    await self.generate_learning_report()
                
                # –°–∏–º—É–ª—è—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –æ–ø—ã—Ç–∞
                await self.simulate_learning_experience()
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏
                await asyncio.sleep(600)  # 10 –º–∏–Ω—É—Ç
                
            except Exception as e:
                self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è {cycle_count}: {e}")
                await asyncio.sleep(300)  # –ü–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    async def simulate_learning_experience(self):
        """–°–∏–º—É–ª—è—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø—ã—Ç–∞ –æ–±—É—á–µ–Ω–∏—è"""
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –æ–ø—ã—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        experience_types = ['trading', 'content', 'prediction', 'risk']
        learning_type = random.choice(experience_types)
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = {
            'timestamp': datetime.now().isoformat(),
            'market_data': {
                'current_price': 45000 + random.uniform(-1000, 1000),
                'volatility': random.uniform(2, 8),
                'volume_24h': random.randint(1000000, 5000000),
                'trend_direction': random.choice(['up', 'down', 'sideways'])
            }
        }
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        action = f"generated_{learning_type}_prediction"
        outcome = {
            'success': random.choice([True, False]),
            'confidence': random.uniform(0.5, 0.9),
            'execution_time': random.uniform(0.1, 2.0)
        }
        
        # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
        reward = random.uniform(0.7, 1.0) if outcome['success'] else random.uniform(0.1, 0.4)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—ã—Ç
        await self.add_learning_experience(context, action, outcome, reward, learning_type)
    
    async def start_learning_engine(self):
        """–ó–∞–ø—É—Å–∫ –¥–≤–∏–∂–∫–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –¥–≤–∏–∂–∫–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è Mirai")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        await self.load_saved_models()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ü–∏–∫–ª
        await self.autonomous_learning_cycle()
    
    async def load_saved_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        for model_type in self.models.keys():
            model_file = Path(self.models_path) / f"{model_type}_model.pkl"
            if model_file.exists():
                try:
                    with open(model_file, 'rb') as f:
                        saved_data = pickle.load(f)
                    
                    self.models[model_type].model = saved_data.get('model')
                    self.models[model_type].scaler = saved_data.get('scaler')
                    self.models[model_type].last_training = saved_data.get('last_training')
                    
                    self.logger.info(f"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_type}")
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_type}: {e}")
    
    def save_models(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        for model_type, model in self.models.items():
            if model.model is not None:
                model_file = Path(self.models_path) / f"{model_type}_model.pkl"
                
                try:
                    save_data = {
                        'model': model.model,
                        'scaler': model.scaler,
                        'last_training': model.last_training,
                        'performance_history': model.performance_history
                    }
                    
                    with open(model_file, 'wb') as f:
                        pickle.dump(save_data, f)
                    
                    self.logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_type}")
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_type}: {e}")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –¥–≤–∏–∂–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
    print("üß† Mirai Machine Learning & Adaptive System")
    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")
    
    learning_engine = MiraiLearningEngine()
    
    try:
        await learning_engine.start_learning_engine()
    except KeyboardInterrupt:
        print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–≤–∏–∂–∫–∞ –æ–±—É—á–µ–Ω–∏—è...")
        learning_engine.save_models()
        learning_engine.logger.info("–î–≤–∏–∂–æ–∫ –æ–±—É—á–µ–Ω–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        learning_engine.save_models()
        learning_engine.logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–≤–∏–∂–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")

if __name__ == "__main__":
    asyncio.run(main())